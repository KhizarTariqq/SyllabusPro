import trainingDataStrings as strings
import spacy
from spacy.tokens import DocBin

nlp = spacy.blank("en")

training_data = [
  (strings.CSC413, [(3905, 3963, "SYLLABUSITEM"), (3964, 4027, "SYLLABUSITEM"), (4028, 4091, "SYLLABUSITEM"), (4092, 4150, "SYLLABUSITEM"), (4151, 4209, "SYLLABUSITEM"), (4210, 4282, "SYLLABUSITEM"), (4283, 4346, "SYLLABUSITEM")]),
  (strings.STA260, [(4469, 4500, "SYLLABUSITEM"), (4501, 4532, "SYLLABUSITEM"), (4533, 4557, "SYLLABUSITEM")]),
  (strings.STA302, [(8707, 8774, "SYLLABUSITEM"), (8775, 8843, "SYLLABUSITEM"), (8844, 8901, "SYLLABUSITEM"), (8902, 8946, "SYLLABUSITEM"), (8947, 8999, "SYLLABUSITEM"), (9024, 9081, "SYLLABUSITEM"), (9082, 9132, "SYLLABUSITEM"), (9133, 9187, "SYLLABUSITEM"), (9188, 9246, "SYLLABUSITEM")]),
  (strings.PHY100, [(4191, 4279, "SYLLABUSITEM"), (4280, 4404, "SYLLABUSITEM"), (4405, 4511, "SYLLABUSITEM"), (4512, 4599, "SYLLABUSITEM")]),
  (strings.CSC263, [(2537, 2576, "SYLLABUSITEM"), (2577, 2616, "SYLLABUSITEM"), (2675, 2713, "SYLLABUSITEM"), (2714, 2770, "SYLLABUSITEM"), (2771, 2810, "SYLLABUSITEM"), (2811, 2876, "SYLLABUSITEM"), (2877, 2945, "SYLLABUSITEM"), (2946, 2979, "SYLLABUSITEM"), (2980, 3046, "SYLLABUSITEM"), (3047, 3133, "SYLLABUSITEM"), (3134, 3183, "SYLLABUSITEM")]),
  (strings.MAT301, [(2537, 2576, "SYLLABUSITEM"), (2577, 2616, "SYLLABUSITEM"), (2675, 2713, "SYLLABUSITEM"), (2714, 2770, "SYLLABUSITEM"), (2771, 2810, "SYLLABUSITEM"), (2811, 2876, "SYLLABUSITEM"), (2877, 2945, "SYLLABUSITEM"), (2946, 2979, "SYLLABUSITEM"), (2980, 3046, "SYLLABUSITEM"), (3047, 3133, "SYLLABUSITEM"), (3134, 3183, "SYLLABUSITEM")]),
  (strings.CSC258, [(2411, 2505, "SYLLABUSITEM"), (2506, 2593, "SYLLABUSITEM"), (2594, 2667, "SYLLABUSITEM"), (2668, 2738, "SYLLABUSITEM"), (2739, 2809, "SYLLABUSITEM"), (2810, 2887, "SYLLABUSITEM"), (2888, 2990, "SYLLABUSITEM"), (2991, 3079, "SYLLABUSITEM")]),
  (strings.CSC324, [(3572, 3616, "SYLLABUSITEM"), (3617, 3676, "SYLLABUSITEM"), (3677, 3737, "SYLLABUSITEM"), (3738, 3756, "SYLLABUSITEM"), (3757, 3804, "SYLLABUSITEM")]),
  

]
# the DocBin will store the example documents
db = DocBin()
for text, annotations in training_data:
    doc = nlp(text)
    ents = []
    for start, end, label in annotations:
        span = doc.char_span(start, end, label=label)
        ents.append(span)
    doc.ents = ents
    db.add(doc)
db.to_disk("./train.spacy")